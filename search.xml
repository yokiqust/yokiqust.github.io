<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[数据预处理与TFRecord]]></title>
      <url>/2017/11/14/DataSet/</url>
      <content type="html"><![CDATA[<p>这篇文章主要说一下TF的数据处理部分。<br><a id="more"></a></p>
<h1 id="数据导入及预处理"><a href="#数据导入及预处理" class="headerlink" title="数据导入及预处理"></a>数据导入及预处理</h1><h2 id="tf-gfile-FastGFile"><a href="#tf-gfile-FastGFile" class="headerlink" title="tf.gfile.FastGFile"></a>tf.gfile.FastGFile</h2><p>首先说一下TF提供的文件处理API， <strong>tf.gfile.FastGFile</strong><br>这个类对Python的文件I/O进行了封装，同时没有thread locking。<br>因为此类提供了 <em>__enter__()</em>  与 <em>__exit__()</em> 两个方法，所以可以与 <strong>with</strong> 关键字一起使用。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>read(n=-1)</em>：将文件作为字符串返回，从当前行开始读取。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>readline()</em>：读取下一行。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>readlines()</em>：将所有行作为List返回。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>write(file_content)</em>：将内容 <strong>追加</strong> 到文件中。</p>
<h2 id="tf-train-Coordinator"><a href="#tf-train-Coordinator" class="headerlink" title="tf.train.Coordinator"></a>tf.train.Coordinator</h2><p>因为要处理大量数据，所以一般使用多线程进行操作，TF同样提供了工具用于线程管理。<br><strong>tf.train.Coordinator</strong> 用来使多个线程同时停止，同时发生异常时向一个可以让其停止的程序报告。<br>其重要方法：<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>tf.train.Coordinator.should_stop</em>：当线程应该被停止时，返回 <strong>True</strong> 。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>tf.train.Coordinator.request_stop</em>：当线程应该被停止时，请求停止。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>tf.train.Coordinator.join</em>：等待，直到指定线程停止。<br>我们首先创建一个 <strong>Coordinator</strong> 对象，然后创建一系列线程。这些线程会一直运行直到 <strong>shoud_stop()</strong> 方法返回 <strong>True</strong> 。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Using Python's threading library.</span></div><div class="line"><span class="keyword">import</span> threading</div><div class="line"></div><div class="line"><span class="comment"># Thread body: loop until the coordinator indicates a stop was requested.</span></div><div class="line"><span class="comment"># If some condition becomes true, ask the coordinator to stop.</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">MyLoop</span><span class="params">(coord)</span>:</span></div><div class="line">  <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</div><div class="line">    ...do something...</div><div class="line">    <span class="keyword">if</span> ...some condition...:</div><div class="line">      coord.request_stop()</div><div class="line"></div><div class="line"><span class="comment"># Main thread: create a coordinator.</span></div><div class="line">coord = tf.train.Coordinator()</div><div class="line"></div><div class="line"><span class="comment"># Create 10 threads that run 'MyLoop()'</span></div><div class="line">threads = [threading.Thread(target=MyLoop, args=(coord,)) <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">10</span>)]</div><div class="line"></div><div class="line"><span class="comment"># Start the threads and wait for all of them to stop.</span></div><div class="line"><span class="keyword">for</span> t <span class="keyword">in</span> threads:</div><div class="line">  t.start()</div><div class="line">coord.join(threads)</div></pre></td></tr></table></figure><br>当线程中抛出异常时，<strong>Coordinator</strong> 可以在将其继续抛出。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">try</span>:</div><div class="line">  <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</div><div class="line">    ...do some work...</div><div class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</div><div class="line">  coord.request_stop(e)</div></pre></td></tr></table></figure><br>为了简化代码可以写为：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> coord.stop_on_exception():</div><div class="line">  <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</div><div class="line">    ...do some work...</div></pre></td></tr></table></figure><br>使用 <strong>stop_on_exception()</strong> 方法可以在异常抛出时，自动停止线程。<br><strong>join(threads=None,stop_grace_period_secs=120,ignore_live_threads=False)</strong>：该方法将会阻塞直到所有线程结束。所有输入的线程将会被 <strong>Coordinator</strong> 使用 <strong>Coordinator.register_thread()</strong> 方法注册。</p>
<h2 id="TFRecord与Example"><a href="#TFRecord与Example" class="headerlink" title="TFRecord与Example"></a>TFRecord与Example</h2><p>在说数据写入之前，先说一下 <strong>TFRecord</strong> 。<br><strong>TFRecord</strong> 数据文件是一种将图像数据与标签统一存储的二进制文件，能更好的利用内存，能够在TF中快速复制，移动，读取，存储等。可以在 <strong>TFRecord</strong> 中直接存储 <em><strong>tf.trian.Example</strong></em>  。对于 <strong>TFRecord</strong> 文件的写入操作可以直接使用 <strong>tf.python_io.TFRecordWriter</strong> 中的 <em>write()</em> 方法完成。<br><strong>Example</strong> 是用来描述输入数据的协议信息。</p>
<h1 id="相关内容"><a href="#相关内容" class="headerlink" title="相关内容"></a>相关内容</h1><h2 id="threading-Thread"><a href="#threading-Thread" class="headerlink" title="threading.Thread"></a>threading.Thread</h2><p>这个类代表被单个线程控制的活动。有两种方式指定活动：通过向构造器中传递一个可调用的对象，或者在其子类中重写 <strong>run()</strong> 方法。<br>当一个 <strong>Thread</strong> 对象被创建后，这个活动将会开始当这个线程的 <strong>start()</strong> 方法被调用。该方法会调用 <strong>run()</strong> 方法。<br>只要该线程的活动开始，则认为该线程的状态为存活（alive）。直到 <strong>run()</strong> 方法结束，该线程都会存活，或者抛出了一个无法解决的异常。使用 <strong>is_alive()</strong> 方法可以判断线程是否还存活。<br>其他线程可调用一个线程的 <strong>join()</strong> 方法，此方法会阻塞调用的线程直到被调用线程结束。</p>
<h2 id="Protocol-Buffer"><a href="#Protocol-Buffer" class="headerlink" title="Protocol Buffer"></a>Protocol Buffer</h2><p><strong>Protocol Buffer</strong> 可以灵活，高效的解决文件序列化以及恢复问题。要使用 <strong>Protocol Buffer</strong> 首先要写一个 <em>.proto</em> 文件，来描述我们想存储的数据结构。根据此文件，<strong>Protocol Buffer</strong> 编译器会创建一个类，来实现自动编码以及从二进制文件中解析数据。</p>
<h3 id="创建-proto-文件"><a href="#创建-proto-文件" class="headerlink" title="创建 .proto 文件"></a>创建 <em>.proto</em> 文件</h3><p>对于每个想要序列化的数据结构为其向 <em>.proto</em> 文件中一个 <em>message</em> ，对信息中的每个字段指明其名字和类型。下面是一个通讯簿的 <em>.proto</em> 文件示例：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">syntax = <span class="string">"proto2"</span>;</div><div class="line"></div><div class="line">package tutorial;</div><div class="line"></div><div class="line">message Person &#123;</div><div class="line">  required <span class="built_in">string</span> name = <span class="number">1</span>;</div><div class="line">  required int32 id = <span class="number">2</span>;</div><div class="line">  optional <span class="built_in">string</span> email = <span class="number">3</span>;</div><div class="line"></div><div class="line">  <span class="keyword">enum</span> PhoneType &#123;</div><div class="line">    MOBILE = <span class="number">0</span>;</div><div class="line">    HOME = <span class="number">1</span>;</div><div class="line">    WORK = <span class="number">2</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  message PhoneNumber &#123;</div><div class="line">    required <span class="built_in">string</span> number = <span class="number">1</span>;</div><div class="line">    optional PhoneType type = <span class="number">2</span> [<span class="keyword">default</span> = HOME];</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  repeated PhoneNumber phones = <span class="number">4</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line">message AddressBook &#123;</div><div class="line">  repeated Person people = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure><br><em>.proto</em> 文件从包声明开始，为了解决命名冲突问题。<br>一个 <em>message</em> 只是将一系列有类型的字段聚合在一起。</p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
            <category> Python </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> Python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow Estimator简介]]></title>
      <url>/2017/11/06/TensorFlow-Estimator/</url>
      <content type="html"><![CDATA[<p>这篇文章主要是简单介绍TensorFlow的高阶API–Estimator，使用此API可以很大程度上简化机器学习的编程工作。<br><a id="more"></a></p>
<h1 id="Estimators"><a href="#Estimators" class="headerlink" title="Estimators"></a>Estimators</h1><p>Estimator中主要封装了以下操作：</p>
<ul>
<li>training</li>
<li>evaluation</li>
<li>prediction</li>
<li>export for serving<h2 id="Estimators的优点"><a href="#Estimators的优点" class="headerlink" title="Estimators的优点"></a>Estimators的优点</h2></li>
<li>可以在本地或者在分布式环境中运行基于Estimators的模型，而不用修改模型。</li>
<li>Estimators简化了模型开发者之间的分享实现</li>
<li>比起底层API，使用Estimators可以更简单的建立模型</li>
<li>Estimators本身是建立在<em><strong>tf.layers</strong></em>，可以简化定制</li>
<li>使用Estimators不必建立计算图  </li>
</ul>
<p>Estimator分为预设Estimator(Pre-made Estimators)和定制Estimator(Custom Estimators)</p>
<h1 id="Pre-made-Estimators"><a href="#Pre-made-Estimators" class="headerlink" title="Pre-made Estimators"></a>Pre-made Estimators</h1><p>预设Estimators能够使我们在更高的概念层面上开发。我们不用再担心建立计算图或者session，因为Estimators会为我们处理这些工作。另外，预设Estimators让我们做最小化的改变而改变模型进行实验。</p>
<h2 id="预设Estimators的结构"><a href="#预设Estimators的结构" class="headerlink" title="预设Estimators的结构"></a>预设Estimators的结构</h2><h3 id="一个或多个数据输入函数-dataset-importing-function"><a href="#一个或多个数据输入函数-dataset-importing-function" class="headerlink" title="一个或多个数据输入函数(dataset importing function)"></a>一个或多个数据输入函数(dataset importing function)</h3><p>比如我们也许可以创建一个函数导入训练集，使用其他函数来导入测试数据集。对于这种输入函数（dataset importing function）必须返回两个对象：</p>
<pre><code>* 一个字典（dictionary），键（keys）是特征名称，值（values）是一个包含相应特征值的Tensor或者SparseTensors
* 一个包含一个或多个labels的Tensor
</code></pre><p>如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(dataset)</span>:</span></div><div class="line">   ...  <span class="comment"># manipulate dataset, extracting feature names and the label</span></div><div class="line">   <span class="keyword">return</span> feature_dict, label</div></pre></td></tr></table></figure></p>
<h3 id="定义特征列（feature-columns）"><a href="#定义特征列（feature-columns）" class="headerlink" title="定义特征列（feature columns）"></a>定义特征列（feature columns）</h3><p>每个 <em>tf.feature_column</em> 标识一个特征名（feature name），特征的类型（type）和任何输入预处理（pre-processing）。下面的代码段创建了三个特征列，可以保存整数或者单浮点数数据。其中前两个特征列简单的指定特征的名称和类型，第三个还指定了一个lambda表达式，用来处理元数据（raw data）:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Define three numeric feature columns.</span></div><div class="line">population = tf.feature_column.numeric_column(<span class="string">'population'</span>)</div><div class="line">crime_rate = tf.feature_column.numeric_column(<span class="string">'crime_rate'</span>)</div><div class="line">median_education = tf.feature_column.numeric_column(<span class="string">'median_education'</span>,</div><div class="line">                    normalizer_fn=<span class="string">'lambda x: x - global_education_mean'</span>)</div></pre></td></tr></table></figure></p>
<h3 id="实例化相关的预设Estimators"><a href="#实例化相关的预设Estimators" class="headerlink" title="实例化相关的预设Estimators"></a>实例化相关的预设Estimators</h3><p>在TensorFlow中预设了很多Estimators，比如DNNClassifier,DNNLinearCombinedClassifier,DNNLinearCombinedRegressor等等。这些Estimators都可以很简单的就能够实例化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Instantiate an estimator, passing the feature columns.</span></div><div class="line">estimator = tf.estimator.Estimator.LinearClassifier(</div><div class="line">    feature_columns=[population, crime_rate, median_education],</div><div class="line">    )</div></pre></td></tr></table></figure>
<h3 id="调用训练，验证或者预测方法"><a href="#调用训练，验证或者预测方法" class="headerlink" title="调用训练，验证或者预测方法"></a>调用训练，验证或者预测方法</h3><p>所有的Estimator都提供了训练（train），验证（evaluate）和预测（predict）方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># my_training_set is the function created in Step 1</span></div><div class="line">estimator.train(input_fn=my_training_set, steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure></p>
<h1 id="Custom-Estimators"><a href="#Custom-Estimators" class="headerlink" title="Custom Estimators"></a>Custom Estimators</h1><p>每个Estimator的核心都是其模型函数（model function）,这个方法用来建立用于训练、验证、预测的计算图。在预设Estimator中，模型函数已经预先设好。</p>
<h2 id="定制Estimators的结构"><a href="#定制Estimators的结构" class="headerlink" title="定制Estimators的结构"></a>定制Estimators的结构</h2><h3 id="实例化一个Estimator"><a href="#实例化一个Estimator" class="headerlink" title="实例化一个Estimator"></a>实例化一个Estimator</h3><p>与预设Estimator相比，当我们创建一个自己的Estimator时，其构造器需要更多的参数用来配置Estimator。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nn = tf.estimator.Estimator(model_fn,</div><div class="line">                            model_dir=<span class="keyword">None</span>,</div><div class="line">                            config=<span class="keyword">None</span>,</div><div class="line">                            params=<span class="keyword">None</span>)</div></pre></td></tr></table></figure><br>Estimator对象包装由于 <em><strong>model_fn</strong></em> 指定的模型，该模型给定输入和其他参数，返回执行训练，评估或预测所需的操作。<br>所有的输出（checkpoints等）都被写入到 <em><strong>model_dir</strong></em> 中，或者其子目录中。<br><strong>config</strong> 参数可以传入一个 <em><strong>RunCongfig</strong></em> 对象，该对象包含运行环境的相关信息。如果 <em><strong>model_fn</strong></em> 中有个参数名为“config”，则会被传入到 <em><strong>model_fn</strong></em> 中。没传入该参数就意味着使用本地的默认设置。<br><strong>params</strong> 参数包含超参数（hyperparameters）。如果 <em><strong>model_fn</strong></em> 中有一个名为“params”的参数，则会被传入 <em><strong>model_fn</strong></em> 中。比如，学习率可以使用该方式传入 <em><strong>model_fn</strong></em> 中。</p>
<h3 id="model-fn的构造"><a href="#model-fn的构造" class="headerlink" title="model_fn的构造"></a>model_fn的构造</h3><p>模型函数的基本结构如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode, params,config)</span>:</span></div><div class="line">   <span class="comment"># Logic to do the following:</span></div><div class="line">   <span class="comment"># 1. Configure the model via TensorFlow operations</span></div><div class="line">   <span class="comment"># 2. Define the loss function for training/evaluation</span></div><div class="line">   <span class="comment"># 3. Define the training operation/optimizer</span></div><div class="line">   <span class="comment"># 4. Generate predictions</span></div><div class="line">   <span class="comment"># 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object</span></div><div class="line">   <span class="keyword">return</span> EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)</div></pre></td></tr></table></figure><br><strong>features</strong>：从 <em><strong>input_fn</strong></em> 中返回的第一个返回值，可以被用来训练，验证和预测。该参数可以是单个Tensor也可以是一个字典。<br><strong>labels</strong>：从 <em><strong>input_fn</strong></em> 中返回的第二个返回值。该参数可以是单个Tensor也可以是一个字典。如果model为 <strong>ModeKeys.PREDICT</strong>，此时 <em>labels</em> 被设置为 <strong>None</strong>。<br><strong>model</strong>：可选的参数。指明该方法是用来训练、验证还是预测。其值为 <strong>tf.estimator.ModeKeys</strong> 中的一个。</p>
<ul>
<li>如果Estimator调用 <em>train()</em> 方法，则 <em><strong>model_fn</strong></em> 接受到的值为 <strong>tf.estimator.ModeKeys.TRAIN</strong>。</li>
<li>如果Estimator调用 <em>evaluate()</em> 方法，则 <em><strong>model_fn</strong></em> 接受到的值为 <strong>tf.estimator.ModeKeys.EVAL</strong>。</li>
<li>如果Estimator调用 <em>predict()</em> 方法，则 <em><strong>model_fn</strong></em> 接受到的值为 <strong>tf.estimator.ModeKeys.PREDICT</strong>。</li>
</ul>
<p>此方法的内部将要完成一下任务：</p>
<ul>
<li>配置模型</li>
<li>定义损失函数</li>
<li>定义训练操作，指定optimizer最小化损失函数。</li>
</ul>
<p>该方法必须返回一个 <strong>tf.estimator.EstimatorSpec</strong> 对象，EstimatorSpec完全定义了由Estimator运行的模型。<br>EstimatorSpec构建如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">__new__(</div><div class="line">    cls,</div><div class="line">    mode,</div><div class="line">    predictions=<span class="keyword">None</span>,</div><div class="line">    loss=<span class="keyword">None</span>,</div><div class="line">    train_op=<span class="keyword">None</span>,</div><div class="line">    eval_metric_ops=<span class="keyword">None</span>,</div><div class="line">    export_outputs=<span class="keyword">None</span>,</div><div class="line">    training_chief_hooks=<span class="keyword">None</span>,</div><div class="line">    training_hooks=<span class="keyword">None</span>,</div><div class="line">    scaffold=<span class="keyword">None</span>,</div><div class="line">    evaluation_hooks=<span class="keyword">None</span></div><div class="line">)</div></pre></td></tr></table></figure><br>    注：__new__(cls,[…])是一个在对象实例化的时候调用的第一个方法。它的第一个参数是这个类，其他的参数是用来直接传递给__init__方法的。<br>其中：</p>
<ul>
<li><em>mode</em>：与 <strong>model_fn</strong> 这种的model相同，一个 <strong>ModeKeys</strong>。</li>
<li><em>predictions</em>：预测得到的Tensor或者Tensor的字典。</li>
<li><em>loss</em>：代表损失值的Tensor，必须是一个标量（scalar）或者其shape为[1]。</li>
<li><em>train_op</em>：训练操作，比如对损失函数的优化器</li>
<li><em>eval_metric_ops</em>：一个可以在验证模式中运行的度量键值对。当运行 <em>evaluate()</em> 方法时，可以直接使用键值对中的键来获取其值。</li>
<li><em>export_outputs</em>：描述要导出到SavedModel的输出签名（output signatures），在服务运行期间使用。此处需要一个 <strong>{name:output}</strong> 字典：<ul>
<li><em>name</em>：此次输出的任意名称。</li>
<li><em>output</em>：一个 <strong>ExportOutput</strong> 对象。</li>
</ul>
</li>
<li><em>training_chief_hooks</em>：</li>
<li><em>training_hooks</em>：</li>
<li><em>scaffold</em>：一个 <strong>tf.train.Scaffold</strong> 对象，可以在初始化，保存和训练中使用。</li>
<li><em>evaluation_hooks</em>：在验证期间运行的 <strong>tf.train.SessionRunHook</strong> 对象。</li>
</ul>
<p>基于mode的值，<strong>EstimatorSpec</strong> 需要不同的值。</p>
<ul>
<li>当mode == <strong>ModeKeys.TRAIN</strong> 时：需要 <em>loss</em> 与 <em>train_op</em></li>
<li>当mode == <strong>ModeKeys.EVAL</strong> 时：需要 <em>loss</em></li>
<li>当mode == <strong>ModeKeys.PREDICT</strong> 时：需要 <em>predictions</em></li>
</ul>
<h3 id="配置神经网络结构"><a href="#配置神经网络结构" class="headerlink" title="配置神经网络结构"></a>配置神经网络结构</h3><p>配置神经网络需要创建并连接输入层、隐藏层和输出层。<br>输出层是一系列的接受特征值的节点，这些特征值通过 <strong>model_fn</strong> 中的 <em>features</em> 参数传入。<br>输入层之后必须通过激活函数与一个或多个隐藏层相连。最后一层隐藏层会与输出层相连。<br><strong>tf.layers</strong> 提供了 <strong>tf.layers.dense</strong> 函数去构建一个全连接网络。其激活函数被 <em><strong>activation</strong></em> 参数控制。<br>其中可以使用的激活函数有：</p>
<ul>
<li><em><strong>tf.nn.relu</strong></em></li>
<li><em><strong>tf.nn.relu6</strong></em></li>
<li><strong>None</strong>，此时输出会直接作为下一层的输入。<br>此外，可以使用 <strong>tf.layers.conv2d()</strong> 进行卷积操作。</li>
</ul>
<h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><p>上面提到 <em><strong>model_fn</strong></em> 函数返回的 <strong>EstimatorSpec</strong> 中必须含有一个 <em>loss</em>，一个代表损失值的Tensor。<br><em><strong>tf.losses</strong></em> 模块提供了各种方便计算损失值的函数：</p>
<ul>
<li><em>absolute_difference(labels,predictions)</em>。使用L1正则项计算损失值。</li>
<li><em>log_loss(labels,predictions)</em>。使用逻辑损失函数计算损失函数，一般用于逻辑回归。</li>
<li><em>mean_squared_error(labels,predictions)</em>。均方误差。</li>
</ul>
<h3 id="定义训练操作"><a href="#定义训练操作" class="headerlink" title="定义训练操作"></a>定义训练操作</h3><p>训练操作定义了TensorFlow在将模型拟合到训练数据时将使用的优化算法。一般来说，是使损失值最小化。<br>一个创建训练操作最简单的方式就是实例化 <strong>tf.train.Optimizer</strong> 的子类，并调用其 <em><strong>minimize</strong></em> 方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">optimizer = tf.train.GradientDescentOptimizer(</div><div class="line">    learning_rate=params[<span class="string">"learning_rate"</span>])</div><div class="line">train_op = optimizer.minimize(</div><div class="line">    loss=loss, global_step=tf.train.get_global_step())</div></pre></td></tr></table></figure></p>
<h1 id="相关内容"><a href="#相关内容" class="headerlink" title="相关内容"></a>相关内容</h1><h2 id="hook"><a href="#hook" class="headerlink" title="hook"></a>hook</h2><p>在Estimator调用 <em>train()</em>,<em>evaluate()</em> 和 <em>predict()</em> 方法时，有一个参数 <em>hooks</em>。此参数是一个 <strong>SessionRunHook</strong> 子类的List，用来在程序运行过程中回调（callback）。<br><strong>SessionRunHook</strong> 类中的主要方法：<br><strong><em>after_create_session(session,coord)</em></strong>：<br>&nbsp;&nbsp;&nbsp;&nbsp;当新的Session创建时，该方法被调用。但是此时计算图已经完成，不再想计算图中加入新的操作。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>session</em>:一个TensorFlow Session对象<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>coord</em>: 一个Coordinator对象，该对象跟踪所有线程。<br><strong><em>after_run(run_context,run_values)</em></strong>：<br>&nbsp;&nbsp;&nbsp;&nbsp;该方法在每次Session调用 <em>run()</em> 方法之后调用。<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>run_context</em>：一个 <strong>SessionRunContext</strong> 对象。<br><strong><em>before_run(run_context)</em></strong>：<br><strong><em>begin()</em></strong>：<br><strong><em>end(session)</em></strong>：</p>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> Estimator </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[残差网络ResNet]]></title>
      <url>/2017/10/19/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9CResNet/</url>
      <content type="html"><![CDATA[<h1 id="深度残差学习（Deep-Residual-Learning）"><a href="#深度残差学习（Deep-Residual-Learning）" class="headerlink" title="深度残差学习（Deep Residual Learning）"></a>深度残差学习（Deep Residual Learning）</h1><h2 id="残差学习（Residual-Learning）"><a href="#残差学习（Residual-Learning）" class="headerlink" title="残差学习（Residual Learning）"></a>残差学习（Residual Learning）</h2><p>对于深度卷积神经网络来说，网络的深度对于模型训练的结果来说至关重要，特别是在图像识别领域。那么由此就产生一个问题：简单的堆积层（layer）可以使网络学习的更好吗？<br><a id="more"></a><br>当一个更深的网络能够开始收敛（converging）时，就会暴露一个退化（degradation）问题：随着网络深度的增加，网络的精度会达到饱和，然后精度就会急速降低。而且，这种退化不是由过拟合（overfitting）引起的，继续向一个适当层数的网络中添加层就会导致更高的训练错误，如下图所示。（为什么？）<br><img src="/2017/10/19/残差网络ResNet/1.png" alt="1.png" title=""><br>训练精度的退化表明不是所有系统都是那么容易优化的。而深度参差学习（deep residual learning）框架可以解决这个退化问题。<br>ResNet通过恒等映射（identity mapping）将一个深层网络退化为一个浅层网络，从而获得更高的训练精度。如果假设多层非线性层（nonlinear layers）可以渐进的拟合复杂函数，这就相当于假设多层非线性层就可以渐进的拟合残差函数（residual function）。从<em>学习恒等映射</em>这点来看，期望映射是H(x)，残差映射为F(x)，其中x为网络第一层的输入，此时F(x)=H(x)-x，则期望输出H(x)=F(x)-x。当F(x)=0时，此时的网络就会退化为一个浅层网络，提高了训练的精度，同时，在极端情况下，当恒等映射达到最优时，网络学习F(x)=0比直接学习F(x)=x要简单很多。从<em>学习残差映射</em>这点来说，根据H(x)=F(x)+x，引入残差之后的映射对输出的变化更加敏感，因为恒等映射将输出的相同部分去掉了，由残差映射F(x)表示变化的部分，而灵敏度大则更利于反向传播时对参数的调整。一个残差学习模块如下：<br><img src="/2017/10/19/残差网络ResNet/2.png" alt="2.png" title=""><br>可以看到恒等映射既没有添加额外的参数，也没有增加计算的复杂度。  </p>
<h2 id="恒等映射（Identity-Mapping）"><a href="#恒等映射（Identity-Mapping）" class="headerlink" title="恒等映射（Identity Mapping）"></a>恒等映射（Identity Mapping）</h2><p>我们将一个构造模块的定义如下：<br><img src="/2017/10/19/残差网络ResNet/3.png" alt="3.png" title=""><br>其中x,y分别表示输入、输出向量。函数F表示要学习的残差映射。F+x的操作被一个快捷连接（shortcut connection）和一个矩阵加法执行。<br>式中x与F必须有相同的维度，如果没有的话，我们可以通过在快接连接上执行一个线性投影（linear projection）Ws来匹配维度：<br><img src="/2017/10/19/残差网络ResNet/4.png" alt="4.png" title=""><br>在实验中已经验证恒等映射足够解决退化问题，所以线性投影只用来匹配维度。<br>在卷积操作中，F+x的操作是作用在两个特征图之间，而且是对应通道间。</p>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><h2 id="残差表示（Residual-Representations）"><a href="#残差表示（Residual-Representations）" class="headerlink" title="残差表示（Residual Representations）"></a>残差表示（Residual Representations）</h2><p>在图像识别领域，VLAD是一种用残差向量（residual vectors）对字典(dictionary)进行编码的表示方法。Fisher Vector可以被看做是VLAD的概率版本。这两种算法在图像检索和分类领域都是强有力的浅层表示方法。对于向量量化，编码残差向量比编码原向量更加高效。（未完）</p>
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> 深度学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 图像处理 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[DehazeNet及其他]]></title>
      <url>/2017/10/12/DehazeNet%E5%8F%8A%E5%85%B6%E4%BB%96/</url>
      <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>DehazeNet是一个端对端（End-to-End）的单张图片去雾系统。<br><a id="more"></a><br>单图像去雾处理是一个挑战ill-posed的问题，已有的方法使用不同的约束或者先验来达到似是而非的去雾效果。图像去雾的难度在于，雾的透射率依赖于雾的深度，而雾的深度在图片中是未知的并且不同位置的雾有不同的深度，而且单张图片的去雾因为有雾区域的判断而尤为艰难。<br>去雾的关键是从输入的有雾图片中估计出图片对应的透射图（medium transmisson map）。而DehazeNet就是一个端对端的可训练的图像去雾系统，使用DehazeNet来估计图片的透射图，使用该透射图对有雾图片逐个像素点恢复，使其恢复成无雾图片。<br>DehazeNet是一个基于深度网络模型的卷积神经网络，其中的层（layers）被特别设计来体现了在图像去雾中既定的假设/先验（assumptions/priors）。其中Maxout层被用来做与雾相关的特征提取。同时，使用一个特别的非线性的激活函数BReLU(bilateral rectified linear unit)来提升恢复图片的质量。  </p>
<h1 id="相关内容"><a href="#相关内容" class="headerlink" title="相关内容"></a>相关内容</h1><h2 id="大气散射模型（Atmospheric-Scattering-Model）"><a href="#大气散射模型（Atmospheric-Scattering-Model）" class="headerlink" title="大气散射模型（Atmospheric Scattering Model）"></a>大气散射模型（Atmospheric Scattering Model）</h2><p>大气散射模型是McCartney为了描述有雾图片信息提出的模型，后进一步被Narasimhan和Nayar发展得来。该模型可以写为：<br><img src="/2017/10/12/DehazeNet及其他/asm.png" alt="asm.png" title=""><br>其中I(x)是观察到的有雾图片，J(x)是对应的无雾图片，t(x)表示透射率，A表示自然光（此处向量对应多通道图片），x表示有雾图片中的像素。<br>其中J(x)t(x)被称为直接衰减（direct attenuation）,描述了真实画面在介质中的衰减。A(1-t(x))被称为空气光(airlight)，表示因散射光引起的场景颜色变化。<br>大气是同质时，t可以被表示为<br><img src="/2017/10/12/DehazeNet及其他/t.png" alt="t.png" title=""><br>其中β表示大气散射系数，d(x)表示场景到相机的距离。显然，当d(x)趋于无穷时，t(x)接近于零，此时A等于I(x)。但是，在实际的照片中距离不可能趋近于无穷，而是一个很远的距离，此时的透射率为一个很小的只t0。此时，可以求出较为稳定的α，即自然光。表示如下：<br><img src="/2017/10/12/DehazeNet及其他/a.png" alt="a.png" title="">  </p>
<h2 id="与雾相关的特征（Haze-Relevant-Features）"><a href="#与雾相关的特征（Haze-Relevant-Features）" class="headerlink" title="与雾相关的特征（Haze-Relevant Features）"></a>与雾相关的特征（Haze-Relevant Features）</h2><p>基于经验观察，已存的去雾方法使用了不同的假设或先验来计算与雾相关的特征。然后通过这些特征来达到去雾的效果。  </p>
<h3 id="暗通道（Dark-Channel）"><a href="#暗通道（Dark-Channel）" class="headerlink" title="暗通道（Dark Channel）"></a>暗通道（Dark Channel）</h3><p>暗通道先验是基于室外图片的经验观察得来的。在大多数室外无雾图片中，至少存在一个颜色通道其中的某些像素的强度值很多低，甚至接近于零。表示如下：<br><img src="/2017/10/12/DehazeNet及其他/dc.png" alt="dc.png" title=""><br>其中Jc是J的一个颜色通道（RGB），Ω(x)表示以x为中心的一块区域。<br>暗通道特征可以直接用来估计透射率 t(x) 正相关于 1-Jdark(x)。</p>
<h3 id="最大对比度（Maximumm-Contrast）"><a href="#最大对比度（Maximumm-Contrast）" class="headerlink" title="最大对比度（Maximumm Contrast）"></a>最大对比度（Maximumm Contrast）</h3><p>因为大气散射，图片的对比度会随着图片的可见度的减小而减小：<br><img src="/2017/10/12/DehazeNet及其他/v.png" alt="v.png" title=""><br>梯度的和表示图片的清晰度，此时t<1。基于这个发现： <img="" src="/2017/10/12/DehazeNet及其他/c.png" alt="c.png" title=""><br>C(x)表示在rxr的区域中的局部对比度最大值。显然对比度特征与透射率之间存在联系，所以图片可以通过最大化对比度来提高可见度。  </1。基于这个发现：></p>
<h3 id="颜色衰减（Color-Attenuation）"><a href="#颜色衰减（Color-Attenuation）" class="headerlink" title="颜色衰减（Color Attenuation）"></a>颜色衰减（Color Attenuation）</h3><p>受到雾的影响，图片的饱和度急剧降低，同时图片的亮度会升高。再根据上面提到的对比度先验，可以根据图片饱和度和亮度的不同来估计雾的浓度：<br><img src="/2017/10/12/DehazeNet及其他/ca.png" alt="ca.png" title=""><br>其中 Iv(x)和Is(x)可以在HSV色彩空间中表示。HSV色彩空间可以通过RGB色彩空间转换获得。<br>颜色衰减特征与d(x)存在正相关关系，也可以用来估计透射率。</p>
<h3 id="色差（Hue-Disparity）"><a href="#色差（Hue-Disparity）" class="headerlink" title="色差（Hue Disparity）"></a>色差（Hue Disparity）</h3><p>原图与其半反像（semi-inverse image）之间的色差可以被用来探测是否是雾。其中半反像：<br><img src="/2017/10/12/DehazeNet及其他/si.png" alt="si.png" title=""><br>对于无雾图来说，是三个通道的半反像中的像素值不都是全反的，导致半反像与原图间的巨大色差。所以色差被表示为：<br><img src="/2017/10/12/DehazeNet及其他/hd.png" alt="hd.png" title=""><br>其中h表示HSV色彩空间中的色彩（hue）通道。所以，透射率与色差之间存在负相关关系。</p>
<h1 id="DehazeNet的层设计"><a href="#DehazeNet的层设计" class="headerlink" title="DehazeNet的层设计"></a>DehazeNet的层设计</h1><p>DehazeNet由级联的卷积层和池化层组成，同时使用适当的非线性激活函数。结构如下：<br><img src="/2017/10/12/DehazeNet及其他/net.png" alt="net.png" title=""><br>分别为：特征提取，多尺度映射，局部极值，非线性回归。</p>
<h2 id="特征提取（Feature-Extration）"><a href="#特征提取（Feature-Extration）" class="headerlink" title="特征提取（Feature Extration）"></a>特征提取（Feature Extration）</h2><p>因为已存的去雾方法基于不同的假设在图片上密集提取与雾相关的特征，密集提取特征相当于在有雾图片上使用适当的卷积核进行卷积操作，然后进行非线性映射。<br>根据这些与雾相关特征的色彩通道的极端处理，使用Maxout单元来进行非线性映射，用以降低输出维度。Maxout单元是用在卷积神经网络中的简单前向传播非线性激活函数。它会通过对k（在该系统中为4）个仿射特征图进行像素最大化操作来产生一个新的特征图。基于Maxout单元，DehazeNet的第一层设计为：<br><img src="/2017/10/12/DehazeNet及其他/maxout.png" alt="maxout.png" title=""><br>Maxout单元示意如下：<br><img src="/2017/10/12/DehazeNet及其他/maxout2.png" alt="maxout2.png" title=""><br><img src="/2017/10/12/DehazeNet及其他/maxout3.png" alt="maxout3.png" title=""><br>相当于原本卷积之后的输出作为隐隐层。<br>Maxout单元将自动学习与雾相关的特征而不是通过已存方法的启发式方法。  </p>
<h2 id="多尺度映射（Multi-Scale-Mapping）"><a href="#多尺度映射（Multi-Scale-Mapping）" class="headerlink" title="多尺度映射（Multi-Scale Mapping）"></a>多尺度映射（Multi-Scale Mapping）</h2><p>多尺度特征已经在去雾中被证明有效。比如在GoogleNet中的inception结构中，并行的使用不同的卷积核进行卷积，能更好的定位输入图片中的边缘对象。在DehazeNet中使用三组卷积核：3x3,5x5,7x7，每种卷积核使用相同的数量进行卷积。所以第二层结构为：<br><img src="/2017/10/12/DehazeNet及其他/msm.png" alt="msm.png" title="">  </p>
<h2 id="局部极值（Local-Extremum）"><a href="#局部极值（Local-Extremum）" class="headerlink" title="局部极值（Local Extremum）"></a>局部极值（Local Extremum）</h2><p>在卷积神经网络的经典结构中，通过考虑每个像素邻域的最大值来克服局部敏感度。此外，基于区域透射率是不变这个假设，局部极值可以克服透射率估计的噪音。DehazeNet第三层：<br><img src="/2017/10/12/DehazeNet及其他/le.png" alt="le.png" title=""><br>与卷积神经网络中的最大池化相比，局部极值可以保证图片的分辨率。  </p>
<h2 id="非线性回归（Non-Linear-Regression）"><a href="#非线性回归（Non-Linear-Regression）" class="headerlink" title="非线性回归（Non-Linear Regression）"></a>非线性回归（Non-Linear Regression）</h2><p>一般的分线性回归激活函数包括Sigmoid和ReLU。其中Sigmoid很容易造成梯度消失，从而使网络收敛很慢，或者取得很差的局部最优解。而ReLU被设计用来解决分类问题，不能很好的应用于回归问题。特别是ReLU当数值小于0时才会抑制数值，这就很容易导致DehazeNet最后一层的溢出（因为透射率在0与1之间）。<br>因此，在DehazeNet中使用了BReLU，图像如下：<br><img src="/2017/10/12/DehazeNet及其他/brelu.png" alt="brelu.png" title=""><br>这样就将透射率t限制在tmin与tmax之间，同时又防止了梯度消失。  </p>
<h1 id="与传统去雾算法的联系"><a href="#与传统去雾算法的联系" class="headerlink" title="与传统去雾算法的联系"></a>与传统去雾算法的联系</h1><p>在DehazeNet的第一层中，使用卷积来实现特征提取。比如暗通道特征，因为是去通道中的最小值，而激活函数是Maxout，是取最大值，则如果卷积核是反向卷积核（中间的值为-1，其余值为0）则就会取到最小值，实现提取暗通道特征。<br>当卷积中使用全通卷积核和反向卷积核就会得到最大特征图和最小特征图，此时就可以将RGB色彩空间转换到HSV色彩空间（两个色彩空间的转换使用到了最大值和最小值），然后就可以将颜色衰减特征和色差特征提取。<br>照片中的白色物体与浓雾区域非常相似，通常都有高亮度值和低饱和度。在大多数雾估计模型中都把白色物体看的很远，导致透射率估计不准确。基于区域景深不变的假设，局部极值克服了这一问题。<br>自然光的估计是根据雾最强的地方，反光最强这个特性。在暗通道优先的方法中，在暗通道中选前0.1%最亮的像素，这些最亮的点就是雾最浓的点，在这些像素中取强度最高的像素，选这个像素作为自然光。根据此方法，在DehazeNet中，取透射率最低的前0.1%的点，因为雾最浓的地方，透射率最低，然后将这些点映射到灰度图上，因为灰度图的像素点可以直接表示光的强度，从灰度图上去最亮的像素作为自然光。</p>
<h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><h2 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h2><p>在去雾训练中很难收集到有雾和无雾的对应的照片。所以在DehazeNet中使用合成的照片进行训练。照片的合成基于两个假设：1,照片内容是透射率独立的，即相同的照片可以显示任意的透射率。2，透射率在一定区域内是不变的。照片合成后从这些照片中随机采样，每个样例都是16x16。  </p>
<h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><p>在DehazeNet中，监督学习是为了获得RGB图片与透射率之间的映射关系，使用均方误差作为损失函数：<br><img src="/2017/10/12/DehazeNet及其他/mse.png" alt="mse.png" title="">  </p>
<h1 id="导向滤波"><a href="#导向滤波" class="headerlink" title="导向滤波"></a>导向滤波</h1><p>使用导向滤波算法精细化透射率图，因为DehazeNet得到的透射率图中的像素点为该区域的透射率，使用导向滤波计算出每个像素点的透射率。<br><img src="/2017/10/12/DehazeNet及其他/g.png" alt="g.png" title="">  </p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><img src="/2017/10/12/DehazeNet及其他/vs.png" alt="vs.png" title="">  
]]></content>
      
        <categories>
            
            <category> 机器学习 </category>
            
            <category> 深度学习 </category>
            
            <category> 卷积神经网络 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 图像处理 </tag>
            
            <tag> CNN </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2017/05/11/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<a id="more"></a>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <url>/README.html</url>
      <content type="html"><![CDATA[<p>This my blog,based on HEXO.</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分类]]></title>
      <url>/categories/index.html</url>
      <content type="html"></content>
    </entry>
    
    <entry>
      <title><![CDATA[tags]]></title>
      <url>/tags/index.html</url>
      <content type="html"></content>
    </entry>
    
    <entry>
      <title><![CDATA[links]]></title>
      <url>/links/index.html</url>
      <content type="html"></content>
    </entry>
    
  
</search>
